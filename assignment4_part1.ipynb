{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc373ca44a024aab46754c7150105e4b",
     "grade": false,
     "grade_id": "cell-2ab9369766ad00a6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Assignment 4: Dealing with Sequences Real-World Data (Part I)\n",
    "\n",
    "Welcome to Assignment 4, the last assignment in this course. In this assignment, we will explore the sequence representation of data. Lots of real-world data can be represented as sequences. Among them, text data is typical and widely available, which we will use for this assignment. We will look at the Tweets with the colorful emojis again, but this time we are not going to filter the  textual content. Several toolkits or packages have been developed to process text data. In this assignment, we will rely on the [NLTK](https://www.nltk.org/) package (Natual Language Toolkit).\n",
    "\n",
    "In this assignment, you will: \n",
    "* Tokenize text data and extract ngrams and skipngrams.\n",
    "* Implement the calculation of edit distance. \n",
    "* Find near-duplicate sequences of a given piece of text.  \n",
    "\n",
    "First, let's load the dependencies and the Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb6e553f337c6b9398f650ab43bfe379",
     "grade": false,
     "grade_id": "cell-cf418579e93a7488",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import nltk\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9922be30a2c8524f964591774dc605b4",
     "grade": false,
     "grade_id": "cell-e11195263234723d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"RT @stunnaboyco: @LUSCIOUSLOUIS that's lunchtime 🍩🍫🍫🍨 rite there 👍👍👍👏😊😊😍😍😗 https://t.co/m0Wngznctw\",\n",
       " '@RossoRestaurant looking forward to joining you for lunch tomorrow to celebrate my husbands birthday! 🎂🥂',\n",
       " 'Out wth my lilbro 4 ice-cream🍡🍦🍦🍦 https://t.co/dFEimQiF3n',\n",
       " 'Kuku🍑 le Dickson🍆 tsa ba bangwe di behaviour okare Clientelle funeral cover They can cover up to 15 guys/ladies. #TheLivingSoul👴',\n",
       " 'RT @Thabang92416252: \"@PinexAndApplex: 🍍🍏 @EmteeSA - We up🔥 https://t.co/nGbvFW2CUA\"YEE']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "with open('assets/tweets.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if len(line) > 0:\n",
    "            tweets.append(line.strip())\n",
    "tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "816cbf380261bbb3031afc8c86afa4a0",
     "grade": false,
     "grade_id": "cell-284c00fd413b9d2a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "To construct the sequence representation of the Tweet, we need to *tokenize* each Tweet into a sequence of language units, which in our case are words. For this assignment, we will use the TweetTokenizer API. For some languages, however, tokenization can be challenging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e9d7f4fca3d5ca92c2c6f67169af40f",
     "grade": false,
     "grade_id": "cell-6a45dea40b149a57",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.casual.TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26324d62bf9d759d92492a15565ec2ab",
     "grade": false,
     "grade_id": "cell-80cb7e3a4b3a4e36",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " '@stunnaboyco',\n",
       " ':',\n",
       " '@LUSCIOUSLOUIS',\n",
       " \"that's\",\n",
       " 'lunchtime',\n",
       " '🍩',\n",
       " '🍫',\n",
       " '🍫',\n",
       " '🍨',\n",
       " 'rite',\n",
       " 'there',\n",
       " '👍',\n",
       " '👍',\n",
       " '👍',\n",
       " '👏',\n",
       " '😊',\n",
       " '😊',\n",
       " '😍',\n",
       " '😍',\n",
       " '😗',\n",
       " 'https://t.co/m0Wngznctw']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(tweets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14559c78c7376d59c7f2b2e9660bd7c8",
     "grade": false,
     "grade_id": "cell-73fd7f3fc7b6843a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "For a quick sanity check, we can calculate the word frequency and see which ones are the most frequently used. With the `Counter` object, we can easily obtain the most frequently used words and their numbers of occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "662329091838227049e44792c7b27844",
     "grade": false,
     "grade_id": "cell-fc10bd9f0b788f2d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('!', 4748),\n",
       " (':', 4601),\n",
       " ('RT', 3757),\n",
       " ('️', 2742),\n",
       " ('…', 2713),\n",
       " ('.', 2413),\n",
       " ('🎂', 2135),\n",
       " (',', 2084),\n",
       " ('a', 1830),\n",
       " ('to', 1819),\n",
       " ('the', 1806),\n",
       " ('you', 1670),\n",
       " ('and', 1646),\n",
       " ('🍾', 1413),\n",
       " ('I', 1403),\n",
       " ('🎉', 1294),\n",
       " ('🥂', 1274),\n",
       " ('Happy', 1269),\n",
       " ('🍰', 1226),\n",
       " ('🍻', 1183)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_counter = Counter()\n",
    "for tweet in tweets:\n",
    "    unigram_list = tokenizer.tokenize(tweet)\n",
    "    unigram_counter.update(unigram_list)\n",
    "unigram_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "491ff941b7c4ee1b2b465dcab078fb18",
     "grade": false,
     "grade_id": "cell-730d7652fbd54562",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "One common type of defined sequential patterns are $n$-grams. Particularly, 1-grams are often called \"unigrams\", 2-grams called bigrams, and 3-grams trigrams. Let's examine the bigrams of a Tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d7cb74af105907c269a38c536c951b6",
     "grade": false,
     "grade_id": "cell-ec6dfb4fab22db93",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RT', '@stunnaboyco'),\n",
       " ('@stunnaboyco', ':'),\n",
       " (':', '@LUSCIOUSLOUIS'),\n",
       " ('@LUSCIOUSLOUIS', \"that's\"),\n",
       " (\"that's\", 'lunchtime'),\n",
       " ('lunchtime', '🍩'),\n",
       " ('🍩', '🍫'),\n",
       " ('🍫', '🍫'),\n",
       " ('🍫', '🍨'),\n",
       " ('🍨', 'rite'),\n",
       " ('rite', 'there'),\n",
       " ('there', '👍'),\n",
       " ('👍', '👍'),\n",
       " ('👍', '👍'),\n",
       " ('👍', '👏'),\n",
       " ('👏', '😊'),\n",
       " ('😊', '😊'),\n",
       " ('😊', '😍'),\n",
       " ('😍', '😍'),\n",
       " ('😍', '😗'),\n",
       " ('😗', 'https://t.co/m0Wngznctw')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_list = list(nltk.bigrams(tokenizer.tokenize(tweets[0])))\n",
    "bigram_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "754fd1c3f8855be63f16cd3abf87dfe5",
     "grade": false,
     "grade_id": "cell-c91511d320cb99fd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Note that each bigram is represented as a tuple of two strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c0d29c7fbb721dc29f217ac4f576e48",
     "grade": false,
     "grade_id": "cell-2d9294576f9126f9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 1. Find the most frequent bigrams (20 pts)\n",
    "\n",
    "Please complete the `freq_bigram` function to find the $n$ most frequent bigrams. Your function should return a list of `top_n` tuples. Each of the tuples should contain a bigram tuple (such as ('👍', '👏')) and its number of occurrence. \n",
    "\n",
    "Hint: The code above, as in previous questions, shows you how to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0b6e1c036ad774572f871b6a513a7f0",
     "grade": false,
     "grade_id": "cell-7c1d2e9dbae5fb22",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "# The notebook setup provides this tokenizer, which is ideal for tweets.\n",
    "tokenizer = nltk.tokenize.casual.TweetTokenizer()\n",
    "\n",
    "def freq_bigrams(tweets, top_n):\n",
    "    \"\"\"\n",
    "    Calculates the most frequent bigrams from a list of tweets.\n",
    "\n",
    "    Args:\n",
    "        tweets (list of str): The list of tweets to process.\n",
    "        top_n (int): The number of most frequent bigrams to return.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: A list of the top_n most frequent bigrams and their counts.\n",
    "    \"\"\"\n",
    "    bigram_counter = Counter()\n",
    "    # Iterate over each tweet in the list\n",
    "    for tweet in tweets:\n",
    "        # Tokenize the current tweet into words using the TweetTokenizer\n",
    "        tokens = tokenizer.tokenize(tweet)\n",
    "        # Generate bigrams and update the counter\n",
    "        bigram_counter.update(nltk.bigrams(tokens))\n",
    "        \n",
    "    # Return the top_n most common bigrams\n",
    "    return bigram_counter.most_common(top_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc14eed0adfb67f63da100414f44f554",
     "grade": false,
     "grade_id": "cell-9c0ffefe2324c16f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('!', '!'), 1334),\n",
       " (('❤', '️'), 600),\n",
       " (('Happy', 'Birthday'), 570),\n",
       " (('’', 's'), 483),\n",
       " (('☕', '️'), 437),\n",
       " (('Happy', 'birthday'), 347),\n",
       " (('🍾', '🥂'), 288),\n",
       " (('🎂', '🎂'), 277),\n",
       " (('🎂', '🍰'), 276),\n",
       " (('🥂', '🍾'), 264)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_bigrams(tweets, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e196071cd82e7b0d31ce070d5453580",
     "grade": true,
     "grade_id": "cell-7216282b01cb79fb",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This code block tests whether the `freq_bigrams` function is implemented correctly.\n",
    "# We hide some tests. Passing the displayed assertions does not guarantee full points.\n",
    "answer = freq_bigrams(tweets, 10)\n",
    "assert answer[0] == (('!', '!'), 1334)\n",
    "assert answer[8] == (('🎂', '🍰'), 276)\n",
    "\n",
    "answer2 = freq_bigrams(tweets[:5000], 5)\n",
    "assert answer2[0] == (('!', '!'), 682)\n",
    "assert answer2[2] == (('Happy', 'Birthday'), 290)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9e3be8ab88e167e2eb3be25e915d289",
     "grade": false,
     "grade_id": "cell-c01ad957f4f2bd7b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Similarly, you can generate trigrams by calling the `nltk.trigrams` API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94accffe36edf6e69721f1431840398c",
     "grade": false,
     "grade_id": "cell-49375454b56d1d2f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2. Find the most frequent skipgrams (20 pts)\n",
    "\n",
    "In this exercise we will compute another commonly defined type of sequential patterns -- the skip-grams. Luckily this is also supported by NLTK. You can find the documentation [here](https://tedboy.github.io/nlps/generated/generated/nltk.skipgrams.html).\n",
    "\n",
    "Please implement the `freq_skipgrams` function to calculate the most frequently used $k$-skip-$n$-grams. Your function should return a list of `top_n` tuples. Each of the tuples should contain a $k$-skip-$n$-gram tuple (such as ('Happy', 'Birthday', '🎂')) and its number of occurrences. \n",
    "\n",
    "Hint: This code will be very similar to the code for the previous question. You must simply adjust the arguments for use with the nltk.skipgrams function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c473798cf66002bd51db598edeb1512",
     "grade": false,
     "grade_id": "cell-bbf383296f8a4dbe",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "# The notebook setup provides this tokenizer.\n",
    "tokenizer = nltk.tokenize.casual.TweetTokenizer()\n",
    "\n",
    "def freq_skipgrams(tweets, n, k, top_n):\n",
    "    \"\"\"\n",
    "    Calculates the most frequent skip-grams from a list of tweets.\n",
    "\n",
    "    Args:\n",
    "        tweets (list of str): The list of tweets to process.\n",
    "        n (int): The size of the n-grams.\n",
    "        k (int): The maximum skip distance.\n",
    "        top_n (int): The number of most frequent skip-grams to return.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: A list of the top_n most frequent skip-grams and their counts.\n",
    "    \"\"\"\n",
    "    skipgram_counter = Counter()\n",
    "    # Iterate over each tweet in the list\n",
    "    for tweet in tweets:\n",
    "        # Tokenize the current tweet into words using the TweetTokenizer\n",
    "        tokens = tokenizer.tokenize(tweet)\n",
    "        # Generate skip-grams and update the counter\n",
    "        skipgram_counter.update(nltk.skipgrams(tokens, n, k))\n",
    "        \n",
    "    # Return the top_n most common skip-grams\n",
    "    return skipgram_counter.most_common(top_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d34f9d5ad331a1f980a252da7ab957ab",
     "grade": false,
     "grade_id": "cell-cbc8e21b75ac865d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "With this function, you can find the 10 most frequent 2-skip-trigram with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('!', '!', '!'), 511),\n",
       " (('️', '❤', '️'), 393),\n",
       " (('❤', '️', '❤'), 365),\n",
       " (('🎂', '🎂', '🎂'), 282),\n",
       " (('Happy', 'Birthday', '!'), 260),\n",
       " (('!', '!', '🎂'), 239),\n",
       " (('️', '️', '️'), 222),\n",
       " (('RT', ':', 'Happy'), 212),\n",
       " (('❤', '️', '️'), 182),\n",
       " (('Birthday', '!', '!'), 161)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_skipgrams(tweets, n=3, k=2, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43d725164477e906d669bcea97531642",
     "grade": true,
     "grade_id": "cell-e1ce15e33533958b",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test\n",
    "# This test cell contains hidden tests. Passing the displayed assertions does not guarantee full points.\n",
    "answer = freq_skipgrams(tweets, n=3, k=2, top_n=10)\n",
    "assert answer[0] == (('!', '!', '!'), 511)\n",
    "assert answer[3] == (('🎂', '🎂', '🎂'), 282)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c25e980eba215bcf85f08eeeb3e1b73d",
     "grade": false,
     "grade_id": "cell-ea2df02e9a9b5b4b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Ngrams and skipgrams are commonly used in text mining, biological sequence mining, and behavior mining tasks.  They are directly used as basis for tasks like phrase detection, named-entity detection, and motif detection, and they are also used as features for building machine learning models in general. Have fun using them in your own data analysis! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
